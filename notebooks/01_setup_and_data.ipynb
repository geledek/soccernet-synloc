{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoccerNet SynLoc: Setup and Data Exploration\n",
    "\n",
    "This notebook covers:\n",
    "1. Environment setup and GPU detection\n",
    "2. Package installation\n",
    "3. SoccerNet data download\n",
    "4. Data exploration and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Detection\n",
    "import torch\n",
    "\n",
    "def detect_gpu():\n",
    "    \"\"\"Detect available GPU and print info.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No GPU available. Training will be slow.\")\n",
    "        return None\n",
    "    \n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Recommend batch size based on GPU\n",
    "    if 'T4' in gpu_name:\n",
    "        print(\"\\nRecommended settings for T4:\")\n",
    "        print(\"  - Batch size: 8-16\")\n",
    "        print(\"  - Input size: 640x640\")\n",
    "        print(\"  - Model: tiny or s\")\n",
    "    elif 'V100' in gpu_name:\n",
    "        print(\"\\nRecommended settings for V100:\")\n",
    "        print(\"  - Batch size: 16-32\")\n",
    "        print(\"  - Input size: 640x640 or 960x960\")\n",
    "        print(\"  - Model: s or m\")\n",
    "    elif 'A100' in gpu_name:\n",
    "        print(\"\\nRecommended settings for A100:\")\n",
    "        print(\"  - Batch size: 32-64\")\n",
    "        print(\"  - Input size: 960x960 or 1280x1280\")\n",
    "        print(\"  - Model: m or l\")\n",
    "    else:\n",
    "        print(f\"\\nUnknown GPU. Adjust batch size based on memory.\")\n",
    "    \n",
    "    return gpu_name\n",
    "\n",
    "GPU_NAME = detect_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Clone repository if not already present\n",
    "    import os\n",
    "    if not os.path.exists('soccernet-synloc'):\n",
    "        !git clone https://github.com/YOUR_USERNAME/soccernet-synloc.git\n",
    "    \n",
    "    # Install package\n",
    "    %cd soccernet-synloc\n",
    "    !pip install -e .[dev] -q\n",
    "    \n",
    "    # Install SoccerNet for data download\n",
    "    !pip install SoccerNet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import synloc\n",
    "from synloc.models import YOLOXPose\n",
    "from synloc.data import SynLocDataset\n",
    "\n",
    "print(f\"synloc package loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download SoccerNet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive for persistent storage\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    DATA_ROOT = Path('/content/drive/MyDrive/SoccerNet/synloc')\n",
    "else:\n",
    "    DATA_ROOT = Path('./data/synloc')\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data root: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SoccerNet SynLoc dataset\n",
    "from SoccerNet.Downloader import SoccerNetDownloader\n",
    "\n",
    "downloader = SoccerNetDownloader(LocalDirectory=str(DATA_ROOT))\n",
    "\n",
    "# Download synloc task data\n",
    "# You'll need your SoccerNet credentials\n",
    "downloader.downloadDataTask(\n",
    "    task=\"synloc\",\n",
    "    split=[\"train\", \"valid\", \"test\", \"challenge\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify downloaded data\n",
    "expected_files = [\n",
    "    'train/annotations.json',\n",
    "    'valid/annotations.json',\n",
    "    'test/annotations.json',\n",
    "    'challenge/annotations.json',\n",
    "]\n",
    "\n",
    "for f in expected_files:\n",
    "    path = DATA_ROOT / f\n",
    "    if path.exists():\n",
    "        print(f\"Found: {f}\")\n",
    "    else:\n",
    "        print(f\"Missing: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Load annotation file\n",
    "with open(DATA_ROOT / 'train/annotations.json') as f:\n",
    "    train_ann = json.load(f)\n",
    "\n",
    "print(f\"Keys: {train_ann.keys()}\")\n",
    "print(f\"Number of images: {len(train_ann['images'])}\")\n",
    "print(f\"Number of annotations: {len(train_ann['annotations'])}\")\n",
    "print(f\"Categories: {train_ann['categories']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore image info\n",
    "img = train_ann['images'][0]\n",
    "print(\"Sample image info:\")\n",
    "for k, v in img.items():\n",
    "    if isinstance(v, list) and len(v) > 5:\n",
    "        print(f\"  {k}: {type(v).__name__}[{len(v)}]\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore annotation info\n",
    "ann = train_ann['annotations'][0]\n",
    "print(\"Sample annotation info:\")\n",
    "for k, v in ann.items():\n",
    "    if isinstance(v, list) and len(v) > 5:\n",
    "        print(f\"  {k}: {type(v).__name__}[{len(v)}]\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count athletes per image\n",
    "athletes_per_img = Counter()\n",
    "for ann in train_ann['annotations']:\n",
    "    athletes_per_img[ann['image_id']] += 1\n",
    "\n",
    "counts = list(athletes_per_img.values())\n",
    "print(f\"Athletes per image:\")\n",
    "print(f\"  Min: {min(counts)}\")\n",
    "print(f\"  Max: {max(counts)}\")\n",
    "print(f\"  Mean: {np.mean(counts):.1f}\")\n",
    "print(f\"  Median: {np.median(counts):.1f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(counts, bins=30, edgecolor='black')\n",
    "plt.xlabel('Number of Athletes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Athletes per Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze keypoints\n",
    "keypoint_names = train_ann['categories'][0].get('keypoints', ['pelvis', 'pelvis_ground'])\n",
    "print(f\"Keypoint names: {keypoint_names}\")\n",
    "\n",
    "# Check keypoint visibility\n",
    "visibility_counts = {name: {'visible': 0, 'occluded': 0, 'not_labeled': 0} \n",
    "                     for name in keypoint_names}\n",
    "\n",
    "for ann in train_ann['annotations']:\n",
    "    kps = np.array(ann['keypoints']).reshape(-1, 3)\n",
    "    for i, name in enumerate(keypoint_names):\n",
    "        v = int(kps[i, 2])\n",
    "        if v == 0:\n",
    "            visibility_counts[name]['not_labeled'] += 1\n",
    "        elif v == 1:\n",
    "            visibility_counts[name]['occluded'] += 1\n",
    "        else:\n",
    "            visibility_counts[name]['visible'] += 1\n",
    "\n",
    "print(\"\\nKeypoint visibility:\")\n",
    "for name, counts in visibility_counts.items():\n",
    "    total = sum(counts.values())\n",
    "    print(f\"  {name}:\")\n",
    "    for status, count in counts.items():\n",
    "        print(f\"    {status}: {count} ({100*count/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def visualize_sample(img_info, annotations, data_root, ax=None):\n",
    "    \"\"\"Visualize image with annotations.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Load image\n",
    "    img_path = data_root / 'train' / 'images' / img_info['file_name']\n",
    "    if not img_path.exists():\n",
    "        # Try alternative path\n",
    "        img_path = data_root / img_info['file_name']\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Draw annotations\n",
    "    colors = ['red', 'blue']  # pelvis, pelvis_ground\n",
    "    \n",
    "    for ann in annotations:\n",
    "        # Draw bbox\n",
    "        x, y, w, h = ann['bbox']\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, \n",
    "                              edgecolor='yellow', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Draw keypoints\n",
    "        kps = np.array(ann['keypoints']).reshape(-1, 3)\n",
    "        for i, (kx, ky, v) in enumerate(kps):\n",
    "            if v > 0:\n",
    "                ax.scatter(kx, ky, c=colors[i], s=50, zorder=10)\n",
    "    \n",
    "    ax.set_title(f\"Image {img_info['id']} - {len(annotations)} athletes\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group annotations by image\n",
    "img_to_anns = {}\n",
    "for ann in train_ann['annotations']:\n",
    "    img_id = ann['image_id']\n",
    "    if img_id not in img_to_anns:\n",
    "        img_to_anns[img_id] = []\n",
    "    img_to_anns[img_id].append(ann)\n",
    "\n",
    "# Create image id to info mapping\n",
    "img_id_to_info = {img['id']: img for img in train_ann['images']}\n",
    "\n",
    "# Visualize random samples\n",
    "np.random.seed(42)\n",
    "sample_ids = np.random.choice(list(img_to_anns.keys()), size=4, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax, img_id in zip(axes.flatten(), sample_ids):\n",
    "    try:\n",
    "        visualize_sample(img_id_to_info[img_id], img_to_anns[img_id], DATA_ROOT, ax)\n",
    "    except Exception as e:\n",
    "        ax.set_title(f\"Error loading image {img_id}: {e}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize BEV Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.visualization import draw_pitch, visualize_bev_predictions\n",
    "\n",
    "def visualize_bev_sample(img_info, annotations):\n",
    "    \"\"\"Visualize ground truth BEV positions.\"\"\"\n",
    "    # Extract ground truth positions\n",
    "    positions = []\n",
    "    for ann in annotations:\n",
    "        if 'position_on_pitch' in ann:\n",
    "            positions.append(ann['position_on_pitch'][:2])\n",
    "    \n",
    "    if len(positions) == 0:\n",
    "        print(\"No position_on_pitch data available\")\n",
    "        return\n",
    "    \n",
    "    positions = np.array(positions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax = draw_pitch(ax=ax)\n",
    "    ax.scatter(positions[:, 0], positions[:, 1], \n",
    "               c='red', s=100, marker='o',\n",
    "               edgecolors='white', linewidths=2,\n",
    "               label='Athletes', zorder=10)\n",
    "    ax.set_title(f\"Image {img_info['id']} - BEV View\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize BEV for a sample\n",
    "sample_id = sample_ids[0]\n",
    "visualize_bev_sample(img_id_to_info[sample_id], img_to_anns[sample_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.data import SynLocDataset, get_train_transforms, get_val_transforms\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = SynLocDataset(\n",
    "    ann_file=str(DATA_ROOT / 'train/annotations.json'),\n",
    "    img_dir=str(DATA_ROOT / 'train/images'),\n",
    "    transforms=get_val_transforms(640),  # Use val transforms for visualization\n",
    "    input_size=(640, 640)\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(\"Sample keys:\", sample.keys())\n",
    "print(f\"Image shape: {sample['image'].shape}\")\n",
    "print(f\"Number of bboxes: {len(sample['bboxes'])}\")\n",
    "print(f\"Keypoints shape: {sample['keypoints'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessed sample\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Image with annotations\n",
    "img = sample['image'].permute(1, 2, 0).numpy()\n",
    "# Denormalize\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = img * std + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Preprocessed Image')\n",
    "\n",
    "# Draw keypoints on image\n",
    "kpts = sample['keypoints'].numpy()\n",
    "h, w = sample['image'].shape[1:]\n",
    "for kpt in kpts:\n",
    "    x, y = kpt[0, :2] * w, kpt[0, :2] * h  # Pelvis\n",
    "    axes[0].scatter(x, y, c='red', s=50)\n",
    "    x, y = kpt[1, :2] * w, kpt[1, :2] * h  # Pelvis ground\n",
    "    axes[0].scatter(x, y, c='blue', s=50)\n",
    "\n",
    "# BEV projection\n",
    "if 'position_on_pitch' in sample:\n",
    "    positions = sample['position_on_pitch'].numpy()\n",
    "    axes[1] = draw_pitch(ax=axes[1])\n",
    "    axes[1].scatter(positions[:, 0], positions[:, 1],\n",
    "                   c='red', s=100, marker='o',\n",
    "                   edgecolors='white', linewidths=2)\n",
    "    axes[1].set_title('BEV Positions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=SynLocDataset.collate_fn\n",
    ")\n",
    "\n",
    "# Test batch loading\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Batch contents:\")\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"  {k}: {v.shape}\")\n",
    "    elif isinstance(v, list):\n",
    "        print(f\"  {k}: list[{len(v)}]\")\n",
    "    else:\n",
    "        print(f\"  {k}: {type(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Model Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.models import YOLOXPose\n",
    "\n",
    "# Create model\n",
    "model = YOLOXPose(\n",
    "    variant='tiny',\n",
    "    num_keypoints=2,\n",
    "    input_size=(640, 640)\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images = batch['image']\n",
    "    print(f\"Input shape: {images.shape}\")\n",
    "    \n",
    "    # Get features\n",
    "    feats = model.neck(model.backbone(images))\n",
    "    print(f\"\\nFeature shapes:\")\n",
    "    for i, f in enumerate(feats):\n",
    "        print(f\"  Level {i}: {f.shape}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    results = model.predict(\n",
    "        images,\n",
    "        input_size=(640, 640),\n",
    "        score_thr=0.01\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPredictions for batch:\")\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"  Image {i}: {len(res['bboxes'])} detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Setup complete! Key findings:\n",
    "\n",
    "1. **Dataset**: SoccerNet SynLoc with synthetic images\n",
    "2. **Annotations**: COCO format with 2 keypoints (pelvis, pelvis_ground)\n",
    "3. **Task**: Detect athletes and project to Bird's Eye View\n",
    "\n",
    "Next steps:\n",
    "- Proceed to `02_training.ipynb` for model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
