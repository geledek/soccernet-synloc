{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoccerNet SynLoc: Challenge Submission\n",
    "\n",
    "This notebook covers:\n",
    "1. Running inference on challenge set\n",
    "2. Formatting results for submission\n",
    "3. Creating submission package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    if not os.path.exists('soccernet-synloc'):\n",
    "        !git clone https://github.com/YOUR_USERNAME/soccernet-synloc.git\n",
    "        %cd soccernet-synloc\n",
    "        !pip install -e .[dev] -q\n",
    "    \n",
    "    DATA_ROOT = Path('/content/drive/MyDrive/SoccerNet/synloc')\n",
    "    CHECKPOINT_DIR = Path('/content/drive/MyDrive/SoccerNet/checkpoints')\n",
    "    SUBMISSION_DIR = Path('/content/drive/MyDrive/SoccerNet/submissions')\n",
    "else:\n",
    "    DATA_ROOT = Path('./data/synloc')\n",
    "    CHECKPOINT_DIR = Path('./checkpoints')\n",
    "    SUBMISSION_DIR = Path('./submissions')\n",
    "\n",
    "SUBMISSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint dir: {CHECKPOINT_DIR}\")\n",
    "print(f\"Submission dir: {SUBMISSION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.models import YOLOXPose\n",
    "\n",
    "# Load config\n",
    "config_path = CHECKPOINT_DIR / 'config.json'\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Create model\n",
    "model = YOLOXPose(\n",
    "    variant=config['model_variant'],\n",
    "    num_keypoints=config['num_keypoints'],\n",
    "    input_size=tuple(config['input_size'])\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "checkpoint_path = CHECKPOINT_DIR / 'final_model.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Challenge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.data import SynLocDataset, get_val_transforms\n",
    "\n",
    "# Check challenge set\n",
    "challenge_ann = DATA_ROOT / 'challenge/annotations.json'\n",
    "challenge_img_dir = DATA_ROOT / 'challenge/images'\n",
    "\n",
    "if not challenge_ann.exists():\n",
    "    print(f\"Challenge annotations not found at {challenge_ann}\")\n",
    "    print(\"Please download the challenge set from SoccerNet\")\n",
    "else:\n",
    "    # Load annotations to check\n",
    "    with open(challenge_ann) as f:\n",
    "        ann_data = json.load(f)\n",
    "    print(f\"Challenge set: {len(ann_data['images'])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenge dataset\n",
    "challenge_dataset = SynLocDataset(\n",
    "    ann_file=str(challenge_ann),\n",
    "    img_dir=str(challenge_img_dir),\n",
    "    transforms=get_val_transforms(config['input_size'][0]),\n",
    "    input_size=tuple(config['input_size'])\n",
    ")\n",
    "\n",
    "challenge_loader = DataLoader(\n",
    "    challenge_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=SynLocDataset.collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Challenge dataset: {len(challenge_dataset)} images\")\n",
    "print(f\"Challenge batches: {len(challenge_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.evaluation import run_inference\n",
    "\n",
    "# Use optimized score threshold from validation\n",
    "# Load from evaluation if available, otherwise use default\n",
    "SCORE_THRESHOLD = 0.3  # Adjust based on your validation results\n",
    "\n",
    "# Run inference\n",
    "print(\"Running inference on challenge set...\")\n",
    "results = run_inference(\n",
    "    model,\n",
    "    challenge_loader,\n",
    "    device=device,\n",
    "    score_thr=0.01,  # Low threshold, will filter later\n",
    "    nms_thr=0.65,\n",
    "    max_per_img=100\n",
    ")\n",
    "\n",
    "print(f\"Total detections (raw): {len(results)}\")\n",
    "\n",
    "# Filter by score threshold\n",
    "filtered_results = [r for r in results if r['score'] >= SCORE_THRESHOLD]\n",
    "print(f\"Total detections (filtered): {len(filtered_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check detection distribution\n",
    "from collections import Counter\n",
    "\n",
    "detections_per_image = Counter(r['image_id'] for r in filtered_results)\n",
    "counts = list(detections_per_image.values())\n",
    "\n",
    "print(f\"\\nDetections per image:\")\n",
    "print(f\"  Min: {min(counts) if counts else 0}\")\n",
    "print(f\"  Max: {max(counts) if counts else 0}\")\n",
    "print(f\"  Mean: {np.mean(counts) if counts else 0:.1f}\")\n",
    "print(f\"  Images with 0 detections: {len(challenge_dataset) - len(detections_per_image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Format Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synloc.evaluation import format_results_for_submission, create_submission_zip\n",
    "\n",
    "# Create submission directory with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "submission_name = f\"submission_{timestamp}\"\n",
    "submission_path = SUBMISSION_DIR / submission_name\n",
    "submission_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Format results\n",
    "results_path, metadata_path = format_results_for_submission(\n",
    "    results=filtered_results,\n",
    "    score_threshold=SCORE_THRESHOLD,\n",
    "    position_from_keypoint_index=1,  # pelvis_ground\n",
    "    output_dir=str(submission_path)\n",
    ")\n",
    "\n",
    "print(f\"Created:\")\n",
    "print(f\"  {results_path}\")\n",
    "print(f\"  {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results format\n",
    "with open(results_path) as f:\n",
    "    saved_results = json.load(f)\n",
    "\n",
    "print(f\"\\nResults file:\")\n",
    "print(f\"  Number of detections: {len(saved_results)}\")\n",
    "\n",
    "if len(saved_results) > 0:\n",
    "    print(f\"  Sample detection:\")\n",
    "    sample = saved_results[0]\n",
    "    for k, v in sample.items():\n",
    "        if isinstance(v, list) and len(v) > 5:\n",
    "            print(f\"    {k}: list[{len(v)}]\")\n",
    "        else:\n",
    "            print(f\"    {k}: {v}\")\n",
    "\n",
    "with open(metadata_path) as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"\\nMetadata file:\")\n",
    "for k, v in metadata.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Submission Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file\n",
    "zip_path = create_submission_zip(\n",
    "    results_path=results_path,\n",
    "    metadata_path=metadata_path,\n",
    "    output_path=str(SUBMISSION_DIR / f\"{submission_name}.zip\")\n",
    ")\n",
    "\n",
    "print(f\"Created submission zip: {zip_path}\")\n",
    "\n",
    "# Check zip size\n",
    "import os\n",
    "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "print(f\"Zip size: {zip_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify zip contents\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "    print(\"Zip contents:\")\n",
    "    for info in zf.infolist():\n",
    "        print(f\"  {info.filename}: {info.file_size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from synloc.evaluation import visualize_predictions\n",
    "from synloc.visualization import draw_pitch\n",
    "from synloc.data.camera import keypoint_to_world\n",
    "\n",
    "def visualize_challenge_prediction(img_id, results, data_root, ann_data, threshold=0.3):\n",
    "    \"\"\"Visualize predictions for a challenge image.\"\"\"\n",
    "    # Get image info\n",
    "    img_info = next(img for img in ann_data['images'] if img['id'] == img_id)\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = [r for r in results if r['image_id'] == img_id and r['score'] >= threshold]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Image view\n",
    "    img_path = data_root / 'challenge/images' / img_info['file_name']\n",
    "    img = Image.open(img_path)\n",
    "    axes[0].imshow(img)\n",
    "    \n",
    "    # Draw predictions\n",
    "    for pred in preds:\n",
    "        x, y, w, h = pred['bbox']\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, \n",
    "                              edgecolor='green', linewidth=2)\n",
    "        axes[0].add_patch(rect)\n",
    "        \n",
    "        # Draw keypoints\n",
    "        kpts = np.array(pred['keypoints']).reshape(-1, 3)\n",
    "        axes[0].scatter(kpts[0, 0], kpts[0, 1], c='red', s=30, zorder=10)  # pelvis\n",
    "        axes[0].scatter(kpts[1, 0], kpts[1, 1], c='blue', s=30, zorder=10)  # pelvis_ground\n",
    "    \n",
    "    axes[0].set_title(f\"Image {img_id}: {len(preds)} detections\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # BEV view\n",
    "    camera_matrix = torch.tensor(img_info['camera_matrix'], dtype=torch.float32)\n",
    "    undist_poly = torch.tensor(img_info['undist_poly'], dtype=torch.float32)\n",
    "    \n",
    "    positions = []\n",
    "    for pred in preds:\n",
    "        kpts = np.array(pred['keypoints']).reshape(-1, 3)\n",
    "        kpt = torch.tensor(kpts[1, :2], dtype=torch.float32).unsqueeze(0)\n",
    "        kpt_norm = (kpt - torch.tensor([(img_info['width']-1)/2, (img_info['height']-1)/2])) / img_info['width']\n",
    "        \n",
    "        try:\n",
    "            world = keypoint_to_world(camera_matrix, undist_poly, kpt_norm)\n",
    "            positions.append(world[0, :2].numpy())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if positions:\n",
    "        positions = np.array(positions)\n",
    "        axes[1] = draw_pitch(ax=axes[1])\n",
    "        axes[1].scatter(positions[:, 0], positions[:, 1],\n",
    "                       c='red', s=100, marker='o',\n",
    "                       edgecolors='white', linewidths=2,\n",
    "                       zorder=10)\n",
    "    else:\n",
    "        axes[1] = draw_pitch(ax=axes[1])\n",
    "    \n",
    "    axes[1].set_title('BEV Projection')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples\n",
    "np.random.seed(42)\n",
    "sample_ids = np.random.choice(\n",
    "    [img['id'] for img in ann_data['images']], \n",
    "    size=min(4, len(ann_data['images'])), \n",
    "    replace=False\n",
    ")\n",
    "\n",
    "for img_id in sample_ids:\n",
    "    visualize_challenge_prediction(img_id, filtered_results, DATA_ROOT, ann_data, SCORE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUBMISSION READY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSubmission file: {zip_path}\")\n",
    "print(f\"Detections: {len(filtered_results)}\")\n",
    "print(f\"Score threshold: {SCORE_THRESHOLD}\")\n",
    "print(f\"Keypoint index: 1 (pelvis_ground)\")\n",
    "print()\n",
    "print(\"To submit:\")\n",
    "print(\"1. Go to https://eval.ai/web/challenges/challenge-page/XXX\")\n",
    "print(\"2. Select 'SynLoc' phase\")\n",
    "print(f\"3. Upload: {Path(zip_path).name}\")\n",
    "print()\n",
    "print(\"Good luck!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional: Test-Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tta_inference(model, dataloader, device='cuda', scales=[1.0], flip=True):\n",
    "    \"\"\"Run inference with test-time augmentation.\n",
    "    \n",
    "    Args:\n",
    "        model: YOLOX-Pose model.\n",
    "        dataloader: Data loader.\n",
    "        device: Device.\n",
    "        scales: List of scales to use.\n",
    "        flip: Whether to use horizontal flip.\n",
    "    \n",
    "    Returns:\n",
    "        List of results.\n",
    "    \"\"\"\n",
    "    from tqdm.auto import tqdm\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    all_results = []\n",
    "    det_id = 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='TTA Inference'):\n",
    "            images = batch['image'].to(device)\n",
    "            img_ids = batch['img_id']\n",
    "            orig_sizes = batch['orig_size']\n",
    "            \n",
    "            _, _, h, w = images.shape\n",
    "            \n",
    "            # Collect predictions from all augmentations\n",
    "            all_preds = []\n",
    "            \n",
    "            for scale in scales:\n",
    "                if scale != 1.0:\n",
    "                    new_h, new_w = int(h * scale), int(w * scale)\n",
    "                    scaled = F.interpolate(images, (new_h, new_w), mode='bilinear')\n",
    "                else:\n",
    "                    scaled = images\n",
    "                    new_h, new_w = h, w\n",
    "                \n",
    "                # Original\n",
    "                results = model.predict(scaled, input_size=(new_w, new_h), score_thr=0.01)\n",
    "                all_preds.append((results, 1.0, False))\n",
    "                \n",
    "                # Flipped\n",
    "                if flip:\n",
    "                    flipped = torch.flip(scaled, dims=[-1])\n",
    "                    results_flip = model.predict(flipped, input_size=(new_w, new_h), score_thr=0.01)\n",
    "                    all_preds.append((results_flip, scale, True))\n",
    "            \n",
    "            # Merge predictions (simple NMS-based merge)\n",
    "            # For now, just use original predictions\n",
    "            # You can implement more sophisticated merging\n",
    "            results_batch = all_preds[0][0]\n",
    "            \n",
    "            # Format results (same as run_inference)\n",
    "            for img_id, orig_size, results in zip(img_ids, orig_sizes, results_batch):\n",
    "                scale_x = orig_size[0] / w\n",
    "                scale_y = orig_size[1] / h\n",
    "                \n",
    "                bboxes = results['bboxes'].cpu().numpy()\n",
    "                scores = results['scores'].cpu().numpy()\n",
    "                keypoints = results['keypoints'].cpu().numpy()\n",
    "                kpt_scores = results['keypoint_scores'].cpu().numpy()\n",
    "                \n",
    "                for i in range(len(bboxes)):\n",
    "                    x1, y1, x2, y2 = bboxes[i]\n",
    "                    x1, x2 = x1 * scale_x, x2 * scale_x\n",
    "                    y1, y2 = y1 * scale_y, y2 * scale_y\n",
    "                    bbox_w, bbox_h = x2 - x1, y2 - y1\n",
    "                    \n",
    "                    kpts = keypoints[i].copy()\n",
    "                    kpts[:, 0] *= scale_x\n",
    "                    kpts[:, 1] *= scale_y\n",
    "                    \n",
    "                    kpts_flat = []\n",
    "                    for k in range(len(kpts)):\n",
    "                        kpts_flat.extend([\n",
    "                            float(kpts[k, 0]),\n",
    "                            float(kpts[k, 1]),\n",
    "                            float(kpt_scores[i, k])\n",
    "                        ])\n",
    "                    \n",
    "                    result = {\n",
    "                        'id': det_id,\n",
    "                        'image_id': int(img_id),\n",
    "                        'category_id': 1,\n",
    "                        'bbox': [float(x1), float(y1), float(bbox_w), float(bbox_h)],\n",
    "                        'area': float(bbox_w * bbox_h),\n",
    "                        'score': float(scores[i]),\n",
    "                        'keypoints': kpts_flat,\n",
    "                    }\n",
    "                    all_results.append(result)\n",
    "                    det_id += 1\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"TTA function defined. Uncomment below to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run with TTA\n",
    "# tta_results = run_tta_inference(\n",
    "#     model,\n",
    "#     challenge_loader,\n",
    "#     device=device,\n",
    "#     scales=[1.0],  # Add more scales: [0.8, 1.0, 1.2]\n",
    "#     flip=True\n",
    "# )\n",
    "# print(f\"TTA results: {len(tta_results)} detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Submission package created successfully!\n",
    "\n",
    "Files generated:\n",
    "- `results.json`: Detection results in COCO format\n",
    "- `metadata.json`: Score threshold and keypoint index\n",
    "- `submission_YYYYMMDD_HHMMSS.zip`: Ready for upload\n",
    "\n",
    "Model settings used:\n",
    "- Variant: {config['model_variant']}\n",
    "- Input size: {config['input_size']}\n",
    "- Score threshold: {SCORE_THRESHOLD}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
